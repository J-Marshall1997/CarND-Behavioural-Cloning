{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Self Driving Car Nanodegree\n",
    "# Project 3 - Behavioural Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By James Marshall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checklist\n",
    "\n",
    "##Get AWS working\n",
    "##Normalise Steering Values\n",
    "##FitGenerator get better samples_per_epoch and nb_...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Images from files and augment them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "with open('mydata/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "        \n",
    "image_paths = []\n",
    "measurements = []\n",
    "for line in samples:\n",
    "    #Centre Image\n",
    "    source_path = line[0]\n",
    "    path, filename = os.path.split(source_path)\n",
    "    current_path = 'C:\\\\Users\\\\James\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\mydata\\\\IMG' + '\\\\' + filename\n",
    "    current_path.strip()\n",
    "    image_paths.append(current_path)\n",
    "    measurements.append(float(line[3]))\n",
    "    \n",
    "    #Left Image\n",
    "    source_path = line[1]\n",
    "    path, filename = os.path.split(source_path)\n",
    "    current_path = 'C:\\\\Users\\\\James\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\mydata\\\\IMG' + '\\\\' + filename\n",
    "    current_path.strip()\n",
    "    image_paths.append(current_path)\n",
    "    measurements.append(float(line[3]) + 0.25)\n",
    "    #Right Image\n",
    "    source_path = line[2]\n",
    "    path, filename = os.path.split(source_path)\n",
    "    current_path = 'C:\\\\Users\\\\James\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\mydata\\\\IMG' + '\\\\' + filename\n",
    "    current_path.strip()\n",
    "    image_paths.append(current_path)\n",
    "    measurements.append(float(line[3]) - 0.25)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of steering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADv5JREFUeJzt3V2MXGd9x/HvjxhCpVbkbaGp7XaD\nsFTCRQFZISo3VUITh1Rx2hLJqCoucmUhpRKVKrWmXEQFopqbhiIVpJRYGFSRpGmlGBIpcvMi1Iu8\nbAoEHCu1CSlZ2YpNbdIiSlqn/17s43SS7Hpm7N0Zr5/vRxrNOc955sz/nFnPb86rU1VIkvrzhmkX\nIEmaDgNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1Kk10y7gVC655JKanZ2ddhmS\ntKo8+eSTP6qqmWH9zuoAmJ2dZW5ubtplSNKqkuTfRunnLiBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4Z\nAJLUKQNAkjplAEhSpwwASerUWX0lsDTM7I77xur/3M7rV6gSafVxC0CSOmUASFKnDABJ6pQBIEmd\nMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjo1cgAkOS/Jt5J8o41fluSxJAeS3JXkTa39/DZ+sE2fHZjH\nJ1r7M0muXe6FkSSNbpwtgI8D+wfGPwvcVlUbgOPAtta+DTheVe8Abmv9SHI5sAV4F7AJ+EKS886s\nfEnS6RopAJKsA64HvtTGA1wF3NO67AZubMOb2zht+tWt/2bgzqp6qap+ABwErliOhZAkjW/Um8F9\nDvhT4Bfa+MXAj6vqRBufB9a24bXA8wBVdSLJi63/WuDRgXkOvkY6Z3iDOq0WQ7cAkvwWcKSqnhxs\nXqRrDZl2qtcMvt/2JHNJ5o4ePTqsPEnSaRplF9D7gRuSPAfcycKun88BFyQ5uQWxDjjUhueB9QBt\n+luAY4Pti7zmFVV1e1VtrKqNMzMzYy+QJGk0QwOgqj5RVeuqapaFg7gPVdXvAQ8DH2rdtgL3tuE9\nbZw2/aGqqta+pZ0ldBmwAXh82ZZEkjSWM/kPYf4MuDPJZ4BvAXe09juAryY5yMIv/y0AVbUvyd3A\n08AJ4OaqevkM3l+SdAbGCoCqegR4pA0/yyJn8VTVz4Cblnj9rcCt4xYpSVp+XgksSZ0yACSpUwaA\nJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhS\npwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXK\nAJCkThkAktQpA0CSOrVm2gVIGs/sjvvG6v/czutXqBKtdm4BSFKnDABJ6pQBIEmdMgAkqVMGgCR1\nygCQpE4ZAJLUKQNAkjo1NACSvDnJ40m+k2Rfkr9o7ZcleSzJgSR3JXlTaz+/jR9s02cH5vWJ1v5M\nkmtXaqEkScONsgXwEnBVVf0a8G5gU5Irgc8Ct1XVBuA4sK313wYcr6p3ALe1fiS5HNgCvAvYBHwh\nyXnLuTCSpNENDYBa8JM2+sb2KOAq4J7Wvhu4sQ1vbuO06VcnSWu/s6peqqofAAeBK5ZlKSRJYxvp\nGECS85J8GzgC7AW+D/y4qk60LvPA2ja8FngeoE1/Ebh4sH2R10iSJmykAKiql6vq3cA6Fn61v3Ox\nbu05S0xbqv1VkmxPMpdk7ujRo6OUJ0k6DWOdBVRVPwYeAa4ELkhy8m6i64BDbXgeWA/Qpr8FODbY\nvshrBt/j9qraWFUbZ2ZmxilPkjSGUc4CmklyQRv+OeADwH7gYeBDrdtW4N42vKeN06Y/VFXV2re0\ns4QuAzYAjy/XgkiSxjPK/wdwKbC7nbHzBuDuqvpGkqeBO5N8BvgWcEfrfwfw1SQHWfjlvwWgqvYl\nuRt4GjgB3FxVLy/v4kiSRjU0AKrqKeA9i7Q/yyJn8VTVz4CblpjXrcCt45cpSVpuXgksSZ0yACSp\nUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjpl\nAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6tWbaBUhaWbM77hv7Nc/tvH4FKtHZ\nxi0ASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXK\nAJCkThkAktQpA0CSOmUASFKnDABJ6tTQAEiyPsnDSfYn2Zfk4639oiR7kxxozxe29iT5fJKDSZ5K\n8t6BeW1t/Q8k2bpyiyVJGmaULYATwJ9U1TuBK4Gbk1wO7AAerKoNwINtHOA6YEN7bAe+CAuBAdwC\nvA+4ArjlZGhIkiZvaABU1eGq+pc2/J/AfmAtsBnY3brtBm5sw5uBr9SCR4ELklwKXAvsrapjVXUc\n2AtsWtalkSSNbKxjAElmgfcAjwFvq6rDsBASwFtbt7XA8wMvm29tS7W/9j22J5lLMnf06NFxypMk\njWHkAEjy88A/AH9cVf9xqq6LtNUp2l/dUHV7VW2sqo0zMzOjlidJGtNIAZDkjSx8+f9dVf1ja36h\n7dqhPR9p7fPA+oGXrwMOnaJdkjQFo5wFFOAOYH9V/dXApD3AyTN5tgL3DrR/pJ0NdCXwYttF9ABw\nTZIL28Hfa1qbJGkK1ozQ5/3A7wPfTfLt1vbnwE7g7iTbgB8CN7Vp9wMfBA4CPwU+ClBVx5J8Gnii\n9ftUVR1blqWQJI1taABU1T+z+P57gKsX6V/AzUvMaxewa5wCJUkrwyuBJalTBoAkdWqUYwBS12Z3\n3DftEqQV4RaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLU\nKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0y\nACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn1ky7AGmSZnfcN+0SpLOGWwCS1CkDQJI6ZQBIUqcM\nAEnqlAEgSZ3yLCBpyjwzSdMydAsgya4kR5J8b6DtoiR7kxxozxe29iT5fJKDSZ5K8t6B12xt/Q8k\n2boyiyNJGtUou4C+DGx6TdsO4MGq2gA82MYBrgM2tMd24IuwEBjALcD7gCuAW06GhiRpOoYGQFV9\nEzj2mubNwO42vBu4caD9K7XgUeCCJJcC1wJ7q+pYVR0H9vL6UJEkTdDpHgN4W1UdBqiqw0ne2trX\nAs8P9JtvbUu1S6/i/nBpcpb7LKAs0lanaH/9DJLtSeaSzB09enRZi5Mk/b/TDYAX2q4d2vOR1j4P\nrB/otw44dIr216mq26tqY1VtnJmZOc3yJEnDnG4A7AFOnsmzFbh3oP0j7WygK4EX266iB4BrklzY\nDv5e09okSVMy9BhAkq8BvwFckmSehbN5dgJ3J9kG/BC4qXW/H/ggcBD4KfBRgKo6luTTwBOt36eq\n6rUHliVJEzQ0AKrqw0tMunqRvgXcvMR8dgG7xqpOkrRivBWEJHXKAJCkThkAktQpA0CSOmUASFKn\nDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoA\nkKROGQCS1CkDQJI6ZQBIUqfWTLsASWef2R33jdX/uZ3Xr1AlWkluAUhSpwwASeqUu4C0osbdlSBp\nctwCkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ3yNFBJZ8wrh1cntwAkqVMGgCR1ygCQpE55DEBj\n8dYOWg4eMzg7GACd8wtd6pe7gCSpU24BnEP8NS9pHBMPgCSbgL8GzgO+VFU7J13DauEXunR6PMYw\nmokGQJLzgL8BfhOYB55Isqeqnp5kHcvFPzJpMvwxtDImvQVwBXCwqp4FSHInsBlYlQEwLv+IJZ1N\nJh0Aa4HnB8bngfet1Jv5C13SKM7GH2eT+D6adABkkbZ6VYdkO7C9jf4kyTMrXtXJ9/7sss/yEuBH\nyz7X1cf14Do4yfWwYOh6OMPvo18ZpdOkA2AeWD8wvg44NNihqm4Hbp9kUSslyVxVbZx2HdPmenAd\nnOR6WHC2rIdJXwfwBLAhyWVJ3gRsAfZMuAZJEhPeAqiqE0n+CHiAhdNAd1XVvknWIElaMPHrAKrq\nfuD+Sb/vlJwTu7KWgevBdXCS62HBWbEeUlXDe0mSzjneC0iSOmUALKMkNyXZl+R/kyx5hD/JpiTP\nJDmYZMcka5yEJBcl2ZvkQHu+cIl+Lyf5dnucEycDDPtsk5yf5K42/bEks5OvcuWNsB7+IMnRgc//\nD6dR50pKsivJkSTfW2J6kny+raOnkrx30jUaAMvre8DvAN9cqsPA7TCuAy4HPpzk8smUNzE7gAer\nagPwYBtfzH9V1bvb44bJlbcyRvxstwHHq+odwG3A8l99MmVj/I3fNfD5f2miRU7Gl4FNp5h+HbCh\nPbYDX5xATa9iACyjqtpfVcMuXHvldhhV9d/AydthnEs2A7vb8G7gxinWMkmjfLaD6+Ye4Ooki10g\nuZr18Dc+VFV9Ezh2ii6bga/UgkeBC5JcOpnqFhgAk7fY7TDWTqmWlfK2qjoM0J7fukS/NyeZS/Jo\nknMhJEb5bF/pU1UngBeBiydS3eSM+jf+u23Xxz1J1i8y/Vw39e8C/z+AMSX5J+AXF5n0yaq6d5RZ\nLNK26k7FOtV6GGM2v1xVh5K8HXgoyXer6vvLU+FUjPLZnhOf/xCjLOPXga9V1UtJPsbCVtFVK17Z\n2WXqfwsGwJiq6gNnOIuht8NYDU61HpK8kOTSqjrcNmmPLDGPQ+352SSPAO8BVnMAjPLZnuwzn2QN\n8BZOvZtgNRrlli//PjD6t5yDx0JGMPXvAncBTV4Pt8PYA2xtw1uB120ZJbkwyflt+BLg/az+24KP\n8tkOrpsPAQ/VuXcxztD18Jp93TcA+ydY39liD/CRdjbQlcCLJ3edTkxV+VimB/DbLKT6S8ALwAOt\n/ZeA+wf6fRD4VxZ+7X5y2nWvwHq4mIWzfw6054ta+0YW/hc4gF8Hvgt8pz1vm3bdy7Tsr/tsgU8B\nN7ThNwN/DxwEHgfePu2ap7Qe/hLY1z7/h4FfnXbNK7AOvgYcBv6nfS9sAz4GfKxNDwtnS32//RvY\nOOkavRJYkjrlLiBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp/4PmKupl1hOfokA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21c7c836780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 25\n",
    "avg_samples_per_bin = len(measurements)/num_bins\n",
    "\n",
    "hist, bins, _ = plt.hist(measurements, num_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGfSS1DmDXpI6Z9BLUucMeknq3P8CJKMZ6jq5PQ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21c7c8d19e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_probs = []\n",
    "target = avg_samples_per_bin * .5\n",
    "for i in range(num_bins):\n",
    "    if hist[i] < target:\n",
    "        keep_probs.append(1.)\n",
    "    else:\n",
    "        keep_probs.append(1./(hist[i]/target))\n",
    "remove_list = []\n",
    "for i in range(len(measurements)):\n",
    "    for j in range(num_bins):\n",
    "        if measurements[i] > bins[j] and measurements[i] <= bins[j+1]:\n",
    "            # delete from X and y with probability 1 - keep_probs[j]\n",
    "            if np.random.rand() > keep_probs[j]:\n",
    "                remove_list.append(i)\n",
    "image_paths = np.delete(image_paths, remove_list, axis=0)\n",
    "measurements = np.delete(measurements, remove_list)\n",
    "\n",
    "# print histogram again to show more even distribution of steering angles\n",
    "plt.hist(measurements, num_bins)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    #Apply a Gaussian Blur\n",
    "    new_img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    #Following NVidias advice, resize to 66x200x3\n",
    "    #Crop first\n",
    "    new_img = img[50:140,:,:]\n",
    "    new_img = cv2.resize(new_img, (200, 66), interpolation = cv2.INTER_AREA)\n",
    "    #Again following NVidias advice on the model being used, convert to YUV colour space\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV)\n",
    "    return new_img\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Randomly distort the training images to help the model generalise better\n",
    "def random_distort(img):\n",
    "    #Convert to float to allow distortion\n",
    "    new_img = img.astype(float)\n",
    "    \n",
    "    #Adjust brightness of image\n",
    "    value = np.random.randint(-28, 28)\n",
    "    #valid_mask will be false if the brightness adjustment would set the value out of the (0, 255) range\n",
    "    #If false, the brightness will not be adjusted\n",
    "    if value > 0:\n",
    "        valid_mask = (new_img[:,:,0] + value) > 255\n",
    "    else:\n",
    "        valid_mask = (new_img[:,:,0] + value) < 0\n",
    "    new_img[:,:,0] += np.where(valid_mask, 0, value)\n",
    "    \n",
    "    #Randomly shadow the image on a random portion of the image, defined by mid\n",
    "    height ,width = new_img.shape[0:2]\n",
    "    mid = np.random.randint(0, width)\n",
    "    factor = np.random.uniform(0.6,0.8)\n",
    "    if np.random.rand() > .5:\n",
    "        new_img[:, 0:mid, 0] *= factor\n",
    "    else:\n",
    "        new_img[:, mid:width, 0] *= factor\n",
    "    \n",
    "    #Randomly shift the image horizontally and vertically\n",
    "    height ,width = new_img.shape[0:2] #Redundant but helps for clarity\n",
    "    horizon = 2*height / 5\n",
    "    vertical = np.random.randint(-height/8, height/8)\n",
    "    src = np.float32([[0, horizon], [width, horizon], [0, height], [width, height]])\n",
    "    dst = np.float32([[0, horizon+vertical], [width, horizon+vertical], [0, height], [width, height]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    new_img = cv2.warpPerspective(new_img, M, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    #Remember to return the image as a uint8\n",
    "    return new_img.astype(np.uint8)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "image_path_train, image_path_valid, measurements_train, measurements_valid = train_test_split(image_paths, measurements, \n",
    "                                                                                                test_size=0.2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def generator(image_paths, measurements, batch_size=32, valid_flag=False):\n",
    "\n",
    "    image_paths, measurements = shuffle(image_paths, measurements)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        for i in range(len(measurements)):\n",
    "            \n",
    "            image = cv2.imread(image_paths[i])\n",
    "            image = preprocess_image(image)\n",
    "            measurement = measurements[i]\n",
    "            \n",
    "            if valid_flag == False:\n",
    "                    image = random_distort(image)\n",
    "            \n",
    "            X_train.append(image)\n",
    "            y_train.append(measurement)\n",
    "            \n",
    "            if len(X_train) == batch_size:\n",
    "                yield (np.array(X_train), np.array(y_train))\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                image_paths, measurements = shuffle(image_paths, measurements)\n",
    "                \n",
    "            #If the steering angle is significant (> 0.33), flip the image and add it to the training set\n",
    "            if abs(measurement)  > 0.33:\n",
    "                flipped_image = cv2.flip(image, 1)\n",
    "                measurement *= -1\n",
    "                X_train.append(flipped_image)\n",
    "                y_train.append(measurement)\n",
    "                if len(X_train) == batch_size:\n",
    "                    yield (np.array(X_train), np.array(y_train))\n",
    "                    X_train = []\n",
    "                    y_train = []\n",
    "                    image_paths, measurements = shuffle(image_paths, measurements)\n",
    "\n",
    "                \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_generator = generator(image_path_train, measurements_train, batch_size=32, valid_flag=False)\n",
    "validation_generator = generator(image_path_valid, measurements_valid, batch_size=32, valid_flag=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Lambda, Cropping2D, Reshape\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.backend import tf\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=50, epochs=3, validation_steps=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 341s 7s/step - loss: 14.8893 - val_loss: 0.1908\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 329s 7s/step - loss: 2.1299 - val_loss: 0.2878\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 325s 6s/step - loss: 1.4231 - val_loss: 0.2103\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/ 255.0 - 0.5, input_shape=(66,200,3)))\n",
    "#Conv 1\n",
    "model.add(Convolution2D(24, (5, 5)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 2\n",
    "model.add(Convolution2D(36, (5, 5)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 3\n",
    "model.add(Convolution2D(48, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 4\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 5\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#Fully Connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch= 50, \n",
    "                    validation_data=validation_generator, nb_val_samples=5, nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
