{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Self Driving Car Nanodegree\n",
    "# Project 3 - Behavioural Cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By James Marshall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Checklist\n",
    "\n",
    "##Get AWS working\n",
    "##Normalise Steering Values\n",
    "##FitGenerator get better samples_per_epoch and nb_...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Images from files and augment them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "with open('mydata/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "        \n",
    "image_paths = []\n",
    "measurements = []\n",
    "for line in samples:\n",
    "    #Centre Image\n",
    "    source_path = line[0]\n",
    "    path, filename = os.path.split(source_path)\n",
    "    current_path = 'C:\\\\Users\\\\James\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\mydata\\\\IMG' + '\\\\' + filename\n",
    "    current_path.strip()\n",
    "    image_paths.append(current_path)\n",
    "    measurements.append(float(line[3]))\n",
    "    \n",
    "    #Left Image\n",
    "    source_path = line[1]\n",
    "    path, filename = os.path.split(source_path)\n",
    "    current_path = 'C:\\\\Users\\\\James\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\mydata\\\\IMG' + '\\\\' + filename\n",
    "    current_path.strip()\n",
    "    image_paths.append(current_path)\n",
    "    measurements.append(float(line[3]) + 0.25)\n",
    "    #Right Image\n",
    "    source_path = line[2]\n",
    "    path, filename = os.path.split(source_path)\n",
    "    current_path = 'C:\\\\Users\\\\James\\\\Documents\\\\GitHub\\\\CarND-Behavioral-Cloning-P3\\\\mydata\\\\IMG' + '\\\\' + filename\n",
    "    current_path.strip()\n",
    "    image_paths.append(current_path)\n",
    "    measurements.append(float(line[3]) - 0.25)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of steering values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADv5JREFUeJzt3V2MXGd9x/HvjxhCpVbkbaGp7XaD\nsFTCRQFZISo3VUITh1Rx2hLJqCoucmUhpRKVKrWmXEQFopqbhiIVpJRYGFSRpGmlGBIpcvMi1Iu8\nbAoEHCu1CSlZ2YpNbdIiSlqn/17s43SS7Hpm7N0Zr5/vRxrNOc955sz/nFnPb86rU1VIkvrzhmkX\nIEmaDgNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1Kk10y7gVC655JKanZ2ddhmS\ntKo8+eSTP6qqmWH9zuoAmJ2dZW5ubtplSNKqkuTfRunnLiBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4Z\nAJLUKQNAkjplAEhSpwwASerUWX0lsDTM7I77xur/3M7rV6gSafVxC0CSOmUASFKnDABJ6pQBIEmd\nMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjo1cgAkOS/Jt5J8o41fluSxJAeS3JXkTa39/DZ+sE2fHZjH\nJ1r7M0muXe6FkSSNbpwtgI8D+wfGPwvcVlUbgOPAtta+DTheVe8Abmv9SHI5sAV4F7AJ+EKS886s\nfEnS6RopAJKsA64HvtTGA1wF3NO67AZubMOb2zht+tWt/2bgzqp6qap+ABwErliOhZAkjW/Um8F9\nDvhT4Bfa+MXAj6vqRBufB9a24bXA8wBVdSLJi63/WuDRgXkOvkY6Z3iDOq0WQ7cAkvwWcKSqnhxs\nXqRrDZl2qtcMvt/2JHNJ5o4ePTqsPEnSaRplF9D7gRuSPAfcycKun88BFyQ5uQWxDjjUhueB9QBt\n+luAY4Pti7zmFVV1e1VtrKqNMzMzYy+QJGk0QwOgqj5RVeuqapaFg7gPVdXvAQ8DH2rdtgL3tuE9\nbZw2/aGqqta+pZ0ldBmwAXh82ZZEkjSWM/kPYf4MuDPJZ4BvAXe09juAryY5yMIv/y0AVbUvyd3A\n08AJ4OaqevkM3l+SdAbGCoCqegR4pA0/yyJn8VTVz4Cblnj9rcCt4xYpSVp+XgksSZ0yACSpUwaA\nJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhS\npwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXK\nAJCkThkAktQpA0CSOrVm2gVIGs/sjvvG6v/czutXqBKtdm4BSFKnDABJ6pQBIEmdMgAkqVMGgCR1\nygCQpE4ZAJLUKQNAkjo1NACSvDnJ40m+k2Rfkr9o7ZcleSzJgSR3JXlTaz+/jR9s02cH5vWJ1v5M\nkmtXaqEkScONsgXwEnBVVf0a8G5gU5Irgc8Ct1XVBuA4sK313wYcr6p3ALe1fiS5HNgCvAvYBHwh\nyXnLuTCSpNENDYBa8JM2+sb2KOAq4J7Wvhu4sQ1vbuO06VcnSWu/s6peqqofAAeBK5ZlKSRJYxvp\nGECS85J8GzgC7AW+D/y4qk60LvPA2ja8FngeoE1/Ebh4sH2R10iSJmykAKiql6vq3cA6Fn61v3Ox\nbu05S0xbqv1VkmxPMpdk7ujRo6OUJ0k6DWOdBVRVPwYeAa4ELkhy8m6i64BDbXgeWA/Qpr8FODbY\nvshrBt/j9qraWFUbZ2ZmxilPkjSGUc4CmklyQRv+OeADwH7gYeBDrdtW4N42vKeN06Y/VFXV2re0\ns4QuAzYAjy/XgkiSxjPK/wdwKbC7nbHzBuDuqvpGkqeBO5N8BvgWcEfrfwfw1SQHWfjlvwWgqvYl\nuRt4GjgB3FxVLy/v4kiSRjU0AKrqKeA9i7Q/yyJn8VTVz4CblpjXrcCt45cpSVpuXgksSZ0yACSp\nUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjpl\nAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6tWbaBUhaWbM77hv7Nc/tvH4FKtHZ\nxi0ASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXK\nAJCkThkAktQpA0CSOmUASFKnDABJ6tTQAEiyPsnDSfYn2Zfk4639oiR7kxxozxe29iT5fJKDSZ5K\n8t6BeW1t/Q8k2bpyiyVJGmaULYATwJ9U1TuBK4Gbk1wO7AAerKoNwINtHOA6YEN7bAe+CAuBAdwC\nvA+4ArjlZGhIkiZvaABU1eGq+pc2/J/AfmAtsBnY3brtBm5sw5uBr9SCR4ELklwKXAvsrapjVXUc\n2AtsWtalkSSNbKxjAElmgfcAjwFvq6rDsBASwFtbt7XA8wMvm29tS7W/9j22J5lLMnf06NFxypMk\njWHkAEjy88A/AH9cVf9xqq6LtNUp2l/dUHV7VW2sqo0zMzOjlidJGtNIAZDkjSx8+f9dVf1ja36h\n7dqhPR9p7fPA+oGXrwMOnaJdkjQFo5wFFOAOYH9V/dXApD3AyTN5tgL3DrR/pJ0NdCXwYttF9ABw\nTZIL28Hfa1qbJGkK1ozQ5/3A7wPfTfLt1vbnwE7g7iTbgB8CN7Vp9wMfBA4CPwU+ClBVx5J8Gnii\n9ftUVR1blqWQJI1taABU1T+z+P57gKsX6V/AzUvMaxewa5wCJUkrwyuBJalTBoAkdWqUYwBS12Z3\n3DftEqQV4RaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLU\nKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0y\nACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn1ky7AGmSZnfcN+0SpLOGWwCS1CkDQJI6ZQBIUqcM\nAEnqlAEgSZ3yLCBpyjwzSdMydAsgya4kR5J8b6DtoiR7kxxozxe29iT5fJKDSZ5K8t6B12xt/Q8k\n2boyiyNJGtUou4C+DGx6TdsO4MGq2gA82MYBrgM2tMd24IuwEBjALcD7gCuAW06GhiRpOoYGQFV9\nEzj2mubNwO42vBu4caD9K7XgUeCCJJcC1wJ7q+pYVR0H9vL6UJEkTdDpHgN4W1UdBqiqw0ne2trX\nAs8P9JtvbUu1S6/i/nBpcpb7LKAs0lanaH/9DJLtSeaSzB09enRZi5Mk/b/TDYAX2q4d2vOR1j4P\nrB/otw44dIr216mq26tqY1VtnJmZOc3yJEnDnG4A7AFOnsmzFbh3oP0j7WygK4EX266iB4BrklzY\nDv5e09okSVMy9BhAkq8BvwFckmSehbN5dgJ3J9kG/BC4qXW/H/ggcBD4KfBRgKo6luTTwBOt36eq\n6rUHliVJEzQ0AKrqw0tMunqRvgXcvMR8dgG7xqpOkrRivBWEJHXKAJCkThkAktQpA0CSOmUASFKn\nDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoA\nkKROGQCS1CkDQJI6ZQBIUqfWTLsASWef2R33jdX/uZ3Xr1AlWkluAUhSpwwASeqUu4C0osbdlSBp\nctwCkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ3yNFBJZ8wrh1cntwAkqVMGgCR1ygCQpE55DEBj\n8dYOWg4eMzg7GACd8wtd6pe7gCSpU24BnEP8NS9pHBMPgCSbgL8GzgO+VFU7J13DauEXunR6PMYw\nmokGQJLzgL8BfhOYB55Isqeqnp5kHcvFPzJpMvwxtDImvQVwBXCwqp4FSHInsBlYlQEwLv+IJZ1N\nJh0Aa4HnB8bngfet1Jv5C13SKM7GH2eT+D6adABkkbZ6VYdkO7C9jf4kyTMrXtXJ9/7sss/yEuBH\nyz7X1cf14Do4yfWwYOh6OMPvo18ZpdOkA2AeWD8wvg44NNihqm4Hbp9kUSslyVxVbZx2HdPmenAd\nnOR6WHC2rIdJXwfwBLAhyWVJ3gRsAfZMuAZJEhPeAqiqE0n+CHiAhdNAd1XVvknWIElaMPHrAKrq\nfuD+Sb/vlJwTu7KWgevBdXCS62HBWbEeUlXDe0mSzjneC0iSOmUALKMkNyXZl+R/kyx5hD/JpiTP\nJDmYZMcka5yEJBcl2ZvkQHu+cIl+Lyf5dnucEycDDPtsk5yf5K42/bEks5OvcuWNsB7+IMnRgc//\nD6dR50pKsivJkSTfW2J6kny+raOnkrx30jUaAMvre8DvAN9cqsPA7TCuAy4HPpzk8smUNzE7gAer\nagPwYBtfzH9V1bvb44bJlbcyRvxstwHHq+odwG3A8l99MmVj/I3fNfD5f2miRU7Gl4FNp5h+HbCh\nPbYDX5xATa9iACyjqtpfVcMuXHvldhhV9d/AydthnEs2A7vb8G7gxinWMkmjfLaD6+Ye4Ooki10g\nuZr18Dc+VFV9Ezh2ii6bga/UgkeBC5JcOpnqFhgAk7fY7TDWTqmWlfK2qjoM0J7fukS/NyeZS/Jo\nknMhJEb5bF/pU1UngBeBiydS3eSM+jf+u23Xxz1J1i8y/Vw39e8C/z+AMSX5J+AXF5n0yaq6d5RZ\nLNK26k7FOtV6GGM2v1xVh5K8HXgoyXer6vvLU+FUjPLZnhOf/xCjLOPXga9V1UtJPsbCVtFVK17Z\n2WXqfwsGwJiq6gNnOIuht8NYDU61HpK8kOTSqjrcNmmPLDGPQ+352SSPAO8BVnMAjPLZnuwzn2QN\n8BZOvZtgNRrlli//PjD6t5yDx0JGMPXvAncBTV4Pt8PYA2xtw1uB120ZJbkwyflt+BLg/az+24KP\n8tkOrpsPAQ/VuXcxztD18Jp93TcA+ydY39liD/CRdjbQlcCLJ3edTkxV+VimB/DbLKT6S8ALwAOt\n/ZeA+wf6fRD4VxZ+7X5y2nWvwHq4mIWzfw6054ta+0YW/hc4gF8Hvgt8pz1vm3bdy7Tsr/tsgU8B\nN7ThNwN/DxwEHgfePu2ap7Qe/hLY1z7/h4FfnXbNK7AOvgYcBv6nfS9sAz4GfKxNDwtnS32//RvY\nOOkavRJYkjrlLiBJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp/4PmKupl1hOfokA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c5beac2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 25\n",
    "avg_samples_per_bin = len(measurements)/num_bins\n",
    "\n",
    "hist, bins, _ = plt.hist(measurements, num_bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c5be92e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_probs = []\n",
    "target = avg_samples_per_bin\n",
    "for i in range(num_bins):\n",
    "    if hist[i] < target:\n",
    "        keep_probs.append(1.)\n",
    "    else:\n",
    "        keep_probs.append(1./(hist[i]/target))\n",
    "remove_list = []\n",
    "for i in range(len(measurements)):\n",
    "    for j in range(num_bins):\n",
    "        if measurements[i] > bins[j] and measurements[i] <= bins[j+1]:\n",
    "            # delete from X and y with probability 1 - keep_probs[j]\n",
    "            if np.random.rand() > keep_probs[j]:\n",
    "                remove_list.append(i)\n",
    "image_paths = np.delete(image_paths, remove_list, axis=0)\n",
    "measurements = np.delete(measurements, remove_list)\n",
    "\n",
    "# print histogram again to show more even distribution of steering angles\n",
    "plt.hist(measurements, num_bins)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    #Apply a Gaussian Blur\n",
    "    new_img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    #Following NVidias advice, resize to 66x200x3\n",
    "    #Crop first\n",
    "    new_img = img[50:140,:,:]\n",
    "    new_img = cv2.resize(new_img, (200, 66), interpolation = cv2.INTER_AREA)\n",
    "    #Again following NVidias advice on the model being used, convert to YUV colour space\n",
    "    new_img = cv2.cvtColor(new_img, cv2.COLOR_BGR2YUV)\n",
    "    return new_img\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Randomly distort the training images to help the model generalise better\n",
    "def random_distort(img):\n",
    "    #Convert to float to allow distortion\n",
    "    new_img = img.astype(float)\n",
    "    \n",
    "    #Adjust brightness of image\n",
    "    value = np.random.randint(-28, 28)\n",
    "    #valid_mask will be false if the brightness adjustment would set the value out of the (0, 255) range\n",
    "    #If false, the brightness will not be adjusted\n",
    "    if value > 0:\n",
    "        valid_mask = (new_img[:,:,0] + value) > 255\n",
    "    else:\n",
    "        valid_mask = (new_img[:,:,0] + value) < 0\n",
    "    new_img[:,:,0] += np.where(valid_mask, 0, value)\n",
    "    \n",
    "    #Randomly shadow the image on a random portion of the image, defined by mid\n",
    "    height ,width = new_img.shape[0:2]\n",
    "    mid = np.random.randint(0, width)\n",
    "    factor = np.random.uniform(0.6,0.8)\n",
    "    if np.random.rand() > .5:\n",
    "        new_img[:, 0:mid, 0] *= factor\n",
    "    else:\n",
    "        new_img[:, mid:width, 0] *= factor\n",
    "    \n",
    "    #Randomly shift the image horizontally and vertically\n",
    "    height ,width = new_img.shape[0:2] #Redundant but helps for clarity\n",
    "    horizon = 2*height / 5\n",
    "    vertical = np.random.randint(-height/8, height/8)\n",
    "    src = np.float32([[0, horizon], [width, horizon], [0, height], [width, height]])\n",
    "    dst = np.float32([[0, horizon+vertical], [width, horizon+vertical], [0, height], [width, height]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    new_img = cv2.warpPerspective(new_img, M, (width, height), borderMode=cv2.BORDER_REPLICATE)\n",
    "    \n",
    "    #Remember to return the image as a uint8\n",
    "    return new_img.astype(np.uint8)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "image_path_train, image_path_valid, measurements_train, measurements_valid = train_test_split(image_paths, measurements, \n",
    "                                                                                                test_size=0.2)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def generator(image_paths, measurements, batch_size=32, valid_flag=False):\n",
    "\n",
    "    image_paths, measurements = shuffle(image_paths, measurements)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        for i in range(len(measurements)):\n",
    "            \n",
    "            image = cv2.imread(image_paths[i])\n",
    "            image = preprocess_image(image)\n",
    "            measurement = measurements[i]\n",
    "            \n",
    "            if valid_flag == False:\n",
    "                    image = random_distort(image)\n",
    "            \n",
    "            X_train.append(image)\n",
    "            y_train.append(measurement)\n",
    "            \n",
    "            if len(X_train) == batch_size:\n",
    "                yield (np.array(X_train), np.array(y_train))\n",
    "                X_train = []\n",
    "                y_train = []\n",
    "                image_paths, measurements = shuffle(image_paths, measurements)\n",
    "                \n",
    "            #If the steering angle is significant (> 0.33), flip the image and add it to the training set\n",
    "            if abs(measurement)  > 0.33:\n",
    "                flipped_image = cv2.flip(image, 1)\n",
    "                measurement *= -1\n",
    "                X_train.append(flipped_image)\n",
    "                y_train.append(measurement)\n",
    "                if len(X_train) == batch_size:\n",
    "                    yield (np.array(X_train), np.array(y_train))\n",
    "                    X_train = []\n",
    "                    y_train = []\n",
    "                    image_paths, measurements = shuffle(image_paths, measurements)\n",
    "\n",
    "                \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "train_generator = generator(image_path_train, measurements_train, batch_size=32, valid_flag=False)\n",
    "validation_generator = generator(image_path_valid, measurements_valid, batch_size=32, valid_flag=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Lambda, Cropping2D, Reshape\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.backend import tf\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\James\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=50, epochs=3, validation_steps=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 329s 7s/step - loss: 14.2305 - val_loss: 0.5778\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 332s 7s/step - loss: 3.8268 - val_loss: 0.6850\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 342s 7s/step - loss: 2.6943 - val_loss: 0.4960\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/ 255.0 - 0.5, input_shape=(66,200,3)))\n",
    "#Conv 1\n",
    "model.add(Convolution2D(24, (5, 5)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 2\n",
    "model.add(Convolution2D(36, (5, 5)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 3\n",
    "model.add(Convolution2D(48, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 4\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#Conv 5\n",
    "model.add(Convolution2D(64, (3, 3)))\n",
    "model.add(Activation('elu'))\n",
    "#Fully Connected\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "model.fit_generator(train_generator, samples_per_epoch= 50, \n",
    "                    validation_data=validation_generator, nb_val_samples=5, nb_epoch=3)\n",
    "\n",
    "model.save('model.h5')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
